{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "133326bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab9813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed_urls = ['https://inshorts.com/en/read/technology',\n",
    "             'https://inshorts.com/en/read/sports',\n",
    "             'https://inshorts.com/en/read/world']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ee61a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(seed_urls):\n",
    "    news_data = []\n",
    "    for url in seed_urls:\n",
    "        news_category = url.split('/')[-1]\n",
    "        data = requests.get(url)\n",
    "        soup = BeautifulSoup(data.content, 'html.parser')\n",
    "        \n",
    "        news_articles = [{'news_headline': headline.find('span', \n",
    "                                                         attrs={\"itemprop\": \"headline\"}).string,\n",
    "                          'news_article': article.find('div', \n",
    "                                                       attrs={\"itemprop\": \"articleBody\"}).string,\n",
    "                          'news_category': news_category}\n",
    "                         \n",
    "                            for headline, article in \n",
    "                             zip(soup.find_all('div', \n",
    "                                               class_=[\"news-card-title news-right-box\"]),\n",
    "                                 soup.find_all('div', \n",
    "                                               class_=[\"news-card-content news-right-box\"]))\n",
    "                        ]\n",
    "        news_data.extend(news_articles)\n",
    "        \n",
    "    df =  pd.DataFrame(news_data)\n",
    "    df = df[['news_headline', 'news_article', 'news_category']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "444f200e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_headline</th>\n",
       "      <th>news_article</th>\n",
       "      <th>news_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IIT Delhi sets up Centre of Excellence for qua...</td>\n",
       "      <td>IIT Delhi has set up a 'Centre of Excellence o...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google CEO sought to keep 'Incognito' mode iss...</td>\n",
       "      <td>Google CEO Sundar Pichai was warned in 2019 th...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30 companies may have their IPOs in Oct-Nov to...</td>\n",
       "      <td>Thirty companies are looking to jointly raise ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interactive airspace map demarcating zones for...</td>\n",
       "      <td>The Civil Aviation Ministry has released an in...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was a disruptive time for me as a mother, wife...</td>\n",
       "      <td>Huawei CFO Meng Wanzhou, who was freed after h...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Average Indian will have to work over 700 hour...</td>\n",
       "      <td>An average Indian will have to work 724.2 hour...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Space? We've a lot to do on Earth: Gates on bi...</td>\n",
       "      <td>Microsoft's billionaire Co-founder Bill Gates ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>India great example of a country that invested...</td>\n",
       "      <td>Microsoft Co-founder Bill Gates called India \"...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Huawei CFO freed from Canada after 3 years fol...</td>\n",
       "      <td>Huawei CFO Meng Wanzhou has flown home to Chin...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Star Trek actor to fly to space aboard Blue Or...</td>\n",
       "      <td>Actor William Shatner, who played the role of ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       news_headline  \\\n",
       "0  IIT Delhi sets up Centre of Excellence for qua...   \n",
       "1  Google CEO sought to keep 'Incognito' mode iss...   \n",
       "2  30 companies may have their IPOs in Oct-Nov to...   \n",
       "3  Interactive airspace map demarcating zones for...   \n",
       "4  Was a disruptive time for me as a mother, wife...   \n",
       "5  Average Indian will have to work over 700 hour...   \n",
       "6  Space? We've a lot to do on Earth: Gates on bi...   \n",
       "7  India great example of a country that invested...   \n",
       "8  Huawei CFO freed from Canada after 3 years fol...   \n",
       "9  Star Trek actor to fly to space aboard Blue Or...   \n",
       "\n",
       "                                        news_article news_category  \n",
       "0  IIT Delhi has set up a 'Centre of Excellence o...    technology  \n",
       "1  Google CEO Sundar Pichai was warned in 2019 th...    technology  \n",
       "2  Thirty companies are looking to jointly raise ...    technology  \n",
       "3  The Civil Aviation Ministry has released an in...    technology  \n",
       "4  Huawei CFO Meng Wanzhou, who was freed after h...    technology  \n",
       "5  An average Indian will have to work 724.2 hour...    technology  \n",
       "6  Microsoft's billionaire Co-founder Bill Gates ...    technology  \n",
       "7  Microsoft Co-founder Bill Gates called India \"...    technology  \n",
       "8  Huawei CFO Meng Wanzhou has flown home to Chin...    technology  \n",
       "9  Actor William Shatner, who played the role of ...    technology  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = build_dataset(seed_urls)\n",
    "news_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "101d3e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "technology    25\n",
       "world         25\n",
       "sports        24\n",
       "Name: news_category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.news_category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afbefa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'''C:\\Users\\kiras\\nlp''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504cc8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55998802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed13c842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kiras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b7ab089",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "67c88bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.59.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.20.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 2.2.0\n",
      "    Uninstalling en-core-web-sm-2.2.0:\n",
      "      Successfully uninstalled en-core-web-sm-2.2.0\n",
      "Successfully installed en-core-web-sm-3.1.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "671711d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.1.0/ru_core_news_sm-3.1.0-py3-none-any.whl (16.1 MB)\n",
      "Collecting pymorphy2>=0.9\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from ru-core-news-sm==3.1.0) (3.1.3)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "Collecting docopt>=0.6\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (1.20.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (4.59.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\kiras\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->ru-core-news-sm==3.1.0) (1.1.1)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=a533be6522f84922b4703401f166a7261c8f0e5fb464107ee11085d36917f156\n",
      "  Stored in directory: c:\\users\\kiras\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2, ru-core-news-sm\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 ru-core-news-sm-3.1.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "#for russian\n",
    "!python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "423f8c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.ru.Russian at 0x2609eed66d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6df70e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some important text'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing html tags\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text\n",
    "strip_html_tags('<html><h2>Some important text</h2></html>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "66b63a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove accents\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "remove_accented_chars('Sómě Áccěntěd těxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4052c15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You all cannot expand contractions I would think'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expanding contractions\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "expand_contractions(\"Y'all can't expand contractions I'd think\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52ffc60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing special characters\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@!\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc3f88b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my system keep crash his crash yesterday ours crash daily'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "lemmatize_text(remove_special_characters(\"My system keeps crashing! his crashed yesterday, ours crashes daily\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5b3ddd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , stopwords , computer not'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "remove_stopwords(\"The, and, if are stopwords, computer is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "134ad0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All together! Right now! Over me\n",
    "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = expand_contractions(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58d0edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_text': 'Google CEO sought to keep \\'Incognito\\' mode issues out of spotlight, lawsuit alleges. Google CEO Sundar Pichai was warned in 2019 that describing \\'Incognito\\' mode as \"private\" was problematic, yet the issue wasn\\'t addressed because he didn\\'t want the feature \"under the spotlight\", a new court filing alleged. Earlier, users alleged that Google tracked their internet use even in \\'Incognito\\' mode. In the latest filing, users \"anticipate seeking to depose\" Pichai, attorneys said. ',\n",
       " 'clean_text': 'google ceo seek keep incognito mode issue spotlight lawsuit allege google ceo sundar pichai warn describe incognito mode private problematic yet issue not address not want feature spotlight new court filing allege early user allege google track internet use even incognito mode late filing user anticipate seek depose pichai attorney say'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining headline and article text\n",
    "news_df['full_text'] = news_df[\"news_headline\"].map(str)+ '. ' + news_df[\"news_article\"]\n",
    "\n",
    "# pre-process text and store the same\n",
    "news_df['clean_text'] = normalize_corpus(news_df['full_text'])\n",
    "norm_corpus = list(news_df['clean_text'])\n",
    "\n",
    "# show a sample news article\n",
    "news_df.iloc[1][['full_text', 'clean_text']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83400174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
